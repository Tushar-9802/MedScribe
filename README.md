
# MedScribe -- Clinical Documentation Workstation

Google MedGemma Impact Challenge 2026 | Main Track + Novel Task Prize

## Problem

AI documentation tools generate verbose, textbook-style notes. A practicing
nephrologist reports: "More often than not I have to go and edit the notes and
shorten them, because they read like textbook lexicon rather than shorthand
designed to deliver efficient summaries with alacrity." Editing AI-generated
notes often takes longer than writing from scratch.

## Solution

MedScribe generates concise clinical shorthand (~100 words per note) using a
fine-tuned MedGemma model, then provides a suite of clinical intelligence tools
for the complete documentation workflow. The system runs fully offline on
consumer hardware.

## Architecture

Three Google HAI-DEF models in a single pipeline:

```
[Audio Input]
      |
[MedASR -- 105M Conformer, CTC decode, 5.2% WER]
      |
[Transcript -- editable by clinician]
      |
[MedGemma 1.5 4B -- LoRA fine-tuned, 4-bit NF4]
      |
[Structured SOAP Note]
      |
[MedGemma 1.5 4B -- base, instruction-tuned]
      |
[Clinical Intelligence: ICD-10, DDx, Med Check, Summaries, Risk Analysis]
```

| Component             | Model                    | Role                                  |
| --------------------- | ------------------------ | ------------------------------------- |
| Speech Recognition    | MedASR (105M, Conformer) | Medical dictation to text, 5.2% WER   |
| SOAP Generation       | MedGemma 1.5 4B (LoRA)   | Concise structured notes (~100 words) |
| Clinical Intelligence | MedGemma 1.5 4B (base)   | ICD-10, DDx, risk analysis, screening |

## Features

**Voice-to-SOAP** -- Record or upload audio, transcribe via MedASR, generate
SOAP note via fine-tuned MedGemma. Transcript is editable before regeneration.

**Text-to-SOAP** -- Paste a medical encounter transcript, generate a structured
SOAP note. Includes example transcripts for demonstration.

**Clinical Tools** (5 tools, base MedGemma instruction-following):

* ICD-10 Coding -- suggest billing codes from SOAP documentation
* Patient Summary -- plain-language visit summary for patients
* Completeness Check -- identify documentation gaps
* Differential Diagnosis -- ranked DDx with supporting/refuting evidence
* Medication Check -- interactions, contraindications, dosage review

**Patient Intake Analysis** -- structured form input (demographics, history,
medications, lifestyle, labs) analyzed by MedGemma for risk assessment,
differential considerations, recommended screenings, red flags, and clinical
questions the clinician should ask.

## Training

* 712 curated samples generated by GPT-4o with anti-hallucination constraints
* LoRA fine-tuning (rank 16, alpha 32) on MedGemma 1.5 4B
* Anti-hallucination: "Not documented in source" for missing data
* Zero WNL shortcuts enforced in training data
* Validation loss 0.782 < Train loss 0.828 (no overfitting)

## Metrics

| Metric                | Value                                  |
| --------------------- | -------------------------------------- |
| Quality score         | 90/100                                 |
| Section completeness  | 100% (S/O/A/P)                         |
| Hallucinated findings | 0%                                     |
| WNL present           | 0%                                     |
| Avg word count        | 104 words (vs ~200+ for verbose tools) |
| Avg SOAP inference    | ~25s                                   |
| PLAN items per note   | 2-4                                    |

## Hardware

**Development:**

* GPU: NVIDIA RTX 5070 Ti (16GB VRAM)
* OS: Windows 11
* CUDA: 12.8

**Requirements (inference):**

* 8GB+ GPU VRAM (4-bit quantized)
* 16GB+ GPU VRAM (FP16)
* 16GB system RAM

MedASR (~400MB) and MedGemma 4B (4-bit ~3GB / FP16 ~8GB) coexist in VRAM.

## Setup

```bash
git clone https://github.com/Tushar-9802/MedScribe-1.git
cd MedScribe-1

python -m venv venv
source venv/bin/activate      # Linux/Mac
venv\Scripts\activate         # Windows

pip install -r requirements.txt
```

Model weights require a HuggingFace account with access to
`google/medgemma-4b-it` and `google/medasr`.

## Usage

```bash
python app.py
```

Opens a Gradio interface at `http://localhost:7860` with five tabs:
Voice to SOAP, Text to SOAP, Clinical Tools, Patient Analysis, and About.

Click "Load Models" to load MedASR and MedGemma into VRAM before use.

## Project Structure

```
MedScribe-1/
  app.py                          # Gradio UI (main entry point)
  src/
    __init__.py
    pipeline.py                   # MedASR + MedGemma orchestration
    inference.py                  # MedGemma loading, generation, stopping criteria
  models/
    checkpoints/
      medgemma_v2_soap/
        final_model/              # LoRA adapter weights
  data/
    processed/                    # Training data
  train_v2.py                     # LoRA fine-tuning script
  evaluate_v2.py                  # Quality evaluation
  generate_soap_gpt4o.py          # Synthetic training data generation
  test_inference_v3.py            # Inference tests
  test_inference_v4.py            # Extended inference tests
```

## Key Technical Decisions

**MedASR over Whisper:** MedASR is a Google HAI-DEF model purpose-built for
medical speech. CTC decoding with manual vocabulary lookup, stutter-killer
regex for repeated characters, and SentencePiece token cleanup.

**LoRA fine-tuning over full fine-tuning:** 712 samples is too few for full
fine-tuning. LoRA (rank 16, alpha 32) on attention layers preserves base
model capability while learning concise SOAP formatting.

**4-bit NF4 quantization:** Reduces MedGemma from ~8GB FP16 to ~3GB, enabling
co-residency with MedASR on a single 16GB GPU. Negligible quality impact for
this task.

**Greedy decoding:** `do_sample=False` for deterministic, faster inference.
Custom stopping criteria detect complete PLAN sections to avoid truncation.

**Anti-stutter CSS:** Gradio's loading animations cause visible UI jerks.
Suppressed via CSS (`opacity: 1`, `animation: none`, `display: none` on
progress elements) and `container=False` on the Audio component.

## Limitations

* English only (MedASR training constraint)
* Research prototype -- not validated for clinical use
* Training data derived from synthetic encounters
* Inference speed is hardware-dependent
* Clinical tools use base model instruction-following, not fine-tuned
* MedASR CTC output requires post-processing; quality varies with audio

## License

MIT License (code). Model weights subject to Google terms.

## Contact

GitHub: [@Tushar-9802](https://github.com/Tushar-9802)
